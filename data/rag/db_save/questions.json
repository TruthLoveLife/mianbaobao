{
    "questions": [
        "LLMs 存在模型幻觉问题，请问如何处理？",
        "基于LLM+向量库的文档对话 思路是怎么样？",
        "基于LLM+向量库的文档对话 核心技术是什么？",
        "基于LLM+向量库的文档对话 prompt 模板 如何构建？",
        "在基于大语言模型和向量库的文档对话中，如何解决文档切分粒度不好把控的问题？",
        "如果在垂直领域中，基于LLM和向量库的文档对话表现不佳，可以采取哪些方法来改进？",
        "当使用Langchain内置的问答分句功能时发现效果不佳，可以尝试哪些方法来改善？",
        "请解释如何使用向量化表示来判断query和Document之间的相关性？",
        "在上下文建模中，可以采取哪些方法来捕捉上下文信息以提高相关性的判断准确性？",
        "扩展查询时，通常会引入哪些类型的词汇来扩大相关Document的召回范围？",
        "语义匹配模型在评估query和Document间的语义相似度时，可以采用哪些技术或架构？",
        "实时反馈在召回优化中起到什么作用？",
        "多模态信息如何提升召回模型的表达能力和准确性？",
        "在让LLM基于query和context得到高质量response的过程中，数据准备阶段需要注意哪些方面？",
        "选择合适的模型架构对生成高质量response有何影响？",
        "微调和优化过程中可以采用哪些方法来提高模型的表现？",
        "上下文建模对于LLM生成高质量response的重要性体现在哪里？",
        "定期评估模型性能时，可以使用哪些评估指标？收集用户反馈的目的何在？",
        "引入外部知识和资源如何帮助提高LLM的质量？"
    ]
}